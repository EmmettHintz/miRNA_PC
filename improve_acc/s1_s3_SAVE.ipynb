{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from catboost import CatBoostClassifier\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, 2570)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_1_samples = pd.read_csv('../data/cancer/stage_1_prostate_cancer_samples.csv')\n",
    "stage_1_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2570)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_3_samples = pd.read_csv('../data/cancer/stage_3_prostate_cancer_samples.csv')\n",
    "stage_3_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset = pd.concat([stage_1_samples, stage_3_samples], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in Stage column: ['Stage: 1' 'Stage: 3']\n",
      "Class distribution in ID_REF column:\n",
      "ID_REF\n",
      "0    173\n",
      "1    150\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify and clean the Stage column\n",
    "print(\"Unique values in Stage column:\", combined_dataset['Stage'].unique())\n",
    "combined_dataset['Stage'] = combined_dataset['Stage'].str.strip()\n",
    "combined_dataset['ID_REF'] = np.where(combined_dataset['Stage'] == 'Stage: 1', 0, 1)\n",
    "combined_dataset['ID_REF'] = np.where(combined_dataset['Stage'] == 'Stage: 3', 1, combined_dataset['ID_REF'])\n",
    "\n",
    "# Print class distribution to ensure both classes are present\n",
    "print(\"Class distribution in ID_REF column:\")\n",
    "print(combined_dataset['ID_REF'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define process_data function\n",
    "def process_data(data, under_sample_factor=None, over_sample_factor=None):\n",
    "    columns_to_drop = ['Sample_ID', 'Sex', 'Age', 'Stage', 'Disease']\n",
    "    data = data.drop(columns=columns_to_drop, axis=1)\n",
    "    \n",
    "    x = np.array(data.drop([\"ID_REF\"], axis=1)).astype('float')\n",
    "    y = np.array(data[\"ID_REF\"]).astype('int')\n",
    "    feature_names = data.columns[1:]\n",
    "\n",
    "    if under_sample_factor is not None and isinstance(under_sample_factor, float) and 0 < under_sample_factor <= 1:\n",
    "        under_sampler = RandomUnderSampler(sampling_strategy=under_sample_factor)\n",
    "        x, y = under_sampler.fit_resample(x, y)\n",
    "\n",
    "    if over_sample_factor is not None and isinstance(over_sample_factor, float) and 0 < over_sample_factor <= 1:\n",
    "        over_sampler = RandomOverSampler(sampling_strategy=over_sample_factor)\n",
    "        x, y = over_sampler.fit_resample(x, y)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0, stratify=y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "feature_selection_num = 500\n",
    "feature_importance_num = 20\n",
    "pca_components = 100  # Number of principal components for PCA\n",
    "\n",
    "# Process data\n",
    "x_train, x_test, y_train, y_test, feature_names = process_data(combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=10, interval_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_objective(trial):\n",
    "    k = feature_selection_num\n",
    "    \n",
    "    C = trial.suggest_loguniform('C', 1e-3, 1e3)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('skb', SelectKBest(f_classif, k=k)),\n",
    "        ('pca', PCA(n_components=pca_components)),\n",
    "        ('estimator', SVC(C=C, kernel=kernel, random_state=0))\n",
    "    ])\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    scores = cross_val_score(pipe, x_train, y_train, cv=cv, scoring='accuracy')\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_objective(trial):\n",
    "    k = feature_selection_num\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2'])\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('skb', SelectKBest(f_classif, k=k)),\n",
    "        ('pca', PCA(n_components=pca_components)),\n",
    "        ('estimator', RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features, criterion=criterion, random_state=0))\n",
    "    ])\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    scores = cross_val_score(pipe, x_train, y_train, cv=cv, scoring='accuracy')\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_objective(trial):\n",
    "    k = feature_selection_num\n",
    "    \n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 1.0)\n",
    "    depth = trial.suggest_int('depth', 2, 10)\n",
    "    iterations = trial.suggest_int('iterations', 100, 1000)\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('skb', SelectKBest(f_classif, k=k)),\n",
    "        ('pca', PCA(n_components=pca_components)),\n",
    "        ('estimator', CatBoostClassifier(learning_rate=learning_rate, depth=depth, iterations=iterations, verbose=0, random_state=0))\n",
    "    ])\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    scores = cross_val_score(pipe, x_train, y_train, cv=cv, scoring='accuracy')\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save study\n",
    "def save_study(study, filename):\n",
    "    joblib.dump(study, filename)\n",
    "\n",
    "# Function to load study\n",
    "def load_study(filename):\n",
    "    return joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize hyperparameters using Optuna\n",
    "svm_study_filename = 'svm_study_s1_s3.pkl'\n",
    "rf_study_filename = 'rf_study_s1_s3.pkl'\n",
    "catboost_study_filename = 'catboost_study_s1_s3.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Hyperparmeters if not trained already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Hyperparameter Optimization\n",
    "if os.path.exists(svm_study_filename):\n",
    "    svm_study = load_study(svm_study_filename)\n",
    "else:\n",
    "    svm_study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "    svm_study.optimize(svm_objective, n_trials=100)\n",
    "    save_study(svm_study, svm_study_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-14 14:08:49,149] A new study created in memory with name: no-name-bfc2ce8c-64d4-4607-b112-cdecb83d8c73\n",
      "[I 2024-06-14 14:08:52,394] Trial 0 finished with value: 0.635369532428356 and parameters: {'n_estimators': 297, 'max_depth': 20, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 0 with value: 0.635369532428356.\n",
      "[I 2024-06-14 14:08:55,694] Trial 1 finished with value: 0.6160633484162895 and parameters: {'n_estimators': 397, 'max_depth': 2, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 0 with value: 0.635369532428356.\n",
      "[I 2024-06-14 14:09:02,360] Trial 2 finished with value: 0.6273755656108597 and parameters: {'n_estimators': 859, 'max_depth': 10, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 0 with value: 0.635369532428356.\n",
      "[I 2024-06-14 14:09:05,294] Trial 3 finished with value: 0.5889140271493212 and parameters: {'n_estimators': 232, 'max_depth': 27, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 0 with value: 0.635369532428356.\n",
      "[I 2024-06-14 14:09:11,211] Trial 4 finished with value: 0.6429864253393665 and parameters: {'n_estimators': 742, 'max_depth': 7, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 4 with value: 0.6429864253393665.\n",
      "[I 2024-06-14 14:09:17,375] Trial 5 finished with value: 0.623604826546003 and parameters: {'n_estimators': 979, 'max_depth': 32, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 4 with value: 0.6429864253393665.\n",
      "[I 2024-06-14 14:09:22,299] Trial 6 finished with value: 0.627526395173454 and parameters: {'n_estimators': 539, 'max_depth': 9, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 4 with value: 0.6429864253393665.\n",
      "[I 2024-06-14 14:09:25,511] Trial 7 finished with value: 0.5733031674208144 and parameters: {'n_estimators': 322, 'max_depth': 29, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 4 with value: 0.6429864253393665.\n",
      "[I 2024-06-14 14:09:30,316] Trial 8 finished with value: 0.6197586726998492 and parameters: {'n_estimators': 637, 'max_depth': 32, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 4 with value: 0.6429864253393665.\n",
      "[I 2024-06-14 14:09:35,849] Trial 9 finished with value: 0.6082202111613876 and parameters: {'n_estimators': 892, 'max_depth': 11, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 4 with value: 0.6429864253393665.\n",
      "[I 2024-06-14 14:09:40,239] Trial 10 finished with value: 0.6276772247360483 and parameters: {'n_estimators': 704, 'max_depth': 2, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 4 with value: 0.6429864253393665.\n",
      "[I 2024-06-14 14:09:43,169] Trial 11 finished with value: 0.635369532428356 and parameters: {'n_estimators': 123, 'max_depth': 20, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 4 with value: 0.6429864253393665.\n",
      "[I 2024-06-14 14:09:47,810] Trial 12 finished with value: 0.6431372549019608 and parameters: {'n_estimators': 536, 'max_depth': 18, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 12 with value: 0.6431372549019608.\n",
      "[I 2024-06-14 14:09:52,727] Trial 13 finished with value: 0.6509049773755656 and parameters: {'n_estimators': 568, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 13 with value: 0.6509049773755656.\n",
      "[I 2024-06-14 14:09:57,089] Trial 14 finished with value: 0.6354449472096532 and parameters: {'n_estimators': 479, 'max_depth': 16, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 13 with value: 0.6509049773755656.\n",
      "[I 2024-06-14 14:10:02,995] Trial 15 finished with value: 0.6548265460030166 and parameters: {'n_estimators': 604, 'max_depth': 16, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 15 with value: 0.6548265460030166.\n",
      "[I 2024-06-14 14:10:08,123] Trial 16 finished with value: 0.6509803921568628 and parameters: {'n_estimators': 646, 'max_depth': 13, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 15 with value: 0.6548265460030166.\n",
      "[I 2024-06-14 14:10:13,828] Trial 17 finished with value: 0.6431372549019608 and parameters: {'n_estimators': 762, 'max_depth': 13, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 15 with value: 0.6548265460030166.\n",
      "[I 2024-06-14 14:10:18,863] Trial 18 finished with value: 0.6549019607843137 and parameters: {'n_estimators': 633, 'max_depth': 22, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 18 with value: 0.6549019607843137.\n",
      "[I 2024-06-14 14:10:22,965] Trial 19 finished with value: 0.643212669683258 and parameters: {'n_estimators': 441, 'max_depth': 22, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 18 with value: 0.6549019607843137.\n",
      "[I 2024-06-14 14:10:29,068] Trial 20 finished with value: 0.6548265460030166 and parameters: {'n_estimators': 817, 'max_depth': 24, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 18 with value: 0.6549019607843137.\n",
      "[I 2024-06-14 14:10:35,380] Trial 21 finished with value: 0.6509049773755656 and parameters: {'n_estimators': 872, 'max_depth': 25, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 18 with value: 0.6549019607843137.\n",
      "[I 2024-06-14 14:10:40,453] Trial 22 finished with value: 0.6587481146304676 and parameters: {'n_estimators': 656, 'max_depth': 24, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:10:45,560] Trial 23 finished with value: 0.6587481146304676 and parameters: {'n_estimators': 621, 'max_depth': 23, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:10:50,698] Trial 24 finished with value: 0.6587481146304676 and parameters: {'n_estimators': 665, 'max_depth': 24, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:10:56,039] Trial 25 finished with value: 0.6548265460030166 and parameters: {'n_estimators': 706, 'max_depth': 28, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:10:59,874] Trial 26 finished with value: 0.6042986425339366 and parameters: {'n_estimators': 481, 'max_depth': 25, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:11:05,788] Trial 27 finished with value: 0.6509049773755656 and parameters: {'n_estimators': 798, 'max_depth': 22, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:11:10,965] Trial 28 finished with value: 0.6587481146304676 and parameters: {'n_estimators': 667, 'max_depth': 19, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:11:15,747] Trial 29 finished with value: 0.6509049773755656 and parameters: {'n_estimators': 577, 'max_depth': 29, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:11:19,581] Trial 30 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 389, 'max_depth': 26, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:11:24,751] Trial 31 finished with value: 0.6549019607843137 and parameters: {'n_estimators': 679, 'max_depth': 19, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:11:30,176] Trial 32 finished with value: 0.6586726998491704 and parameters: {'n_estimators': 723, 'max_depth': 22, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:11:34,574] Trial 33 finished with value: 0.6431372549019608 and parameters: {'n_estimators': 511, 'max_depth': 23, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:11:40,387] Trial 34 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 779, 'max_depth': 20, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:11:45,578] Trial 35 finished with value: 0.6587481146304676 and parameters: {'n_estimators': 669, 'max_depth': 20, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:11:50,914] Trial 36 finished with value: 0.6390648567119155 and parameters: {'n_estimators': 610, 'max_depth': 27, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:11:56,892] Trial 37 finished with value: 0.6120663650075414 and parameters: {'n_estimators': 994, 'max_depth': 18, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:12:03,803] Trial 38 finished with value: 0.6351432880844645 and parameters: {'n_estimators': 935, 'max_depth': 30, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:12:09,014] Trial 39 finished with value: 0.6199095022624433 and parameters: {'n_estimators': 831, 'max_depth': 24, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:12:13,443] Trial 40 finished with value: 0.6430618401206637 and parameters: {'n_estimators': 397, 'max_depth': 26, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:12:19,046] Trial 41 finished with value: 0.6509803921568628 and parameters: {'n_estimators': 742, 'max_depth': 20, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:12:24,432] Trial 42 finished with value: 0.6587481146304676 and parameters: {'n_estimators': 667, 'max_depth': 20, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:12:29,923] Trial 43 finished with value: 0.6549019607843137 and parameters: {'n_estimators': 684, 'max_depth': 21, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:12:34,927] Trial 44 finished with value: 0.6509803921568628 and parameters: {'n_estimators': 588, 'max_depth': 18, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:12:39,513] Trial 45 finished with value: 0.6431372549019608 and parameters: {'n_estimators': 532, 'max_depth': 24, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:12:43,775] Trial 46 finished with value: 0.6043740573152339 and parameters: {'n_estimators': 635, 'max_depth': 6, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:12:49,841] Trial 47 finished with value: 0.6390648567119155 and parameters: {'n_estimators': 739, 'max_depth': 17, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:12:55,019] Trial 48 finished with value: 0.6587481146304676 and parameters: {'n_estimators': 677, 'max_depth': 14, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:12:59,842] Trial 49 finished with value: 0.6548265460030166 and parameters: {'n_estimators': 611, 'max_depth': 31, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:13:04,088] Trial 50 finished with value: 0.6004524886877828 and parameters: {'n_estimators': 563, 'max_depth': 23, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:13:09,312] Trial 51 finished with value: 0.6549019607843137 and parameters: {'n_estimators': 671, 'max_depth': 19, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:13:14,552] Trial 52 finished with value: 0.6587481146304676 and parameters: {'n_estimators': 659, 'max_depth': 21, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.6587481146304676.\n",
      "[I 2024-06-14 14:13:20,011] Trial 53 finished with value: 0.6625188536953243 and parameters: {'n_estimators': 712, 'max_depth': 16, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:13:25,691] Trial 54 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 777, 'max_depth': 16, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:13:31,359] Trial 55 finished with value: 0.6509049773755656 and parameters: {'n_estimators': 201, 'max_depth': 11, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:13:36,831] Trial 56 finished with value: 0.6548265460030166 and parameters: {'n_estimators': 698, 'max_depth': 17, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:13:42,262] Trial 57 finished with value: 0.6586726998491704 and parameters: {'n_estimators': 720, 'max_depth': 15, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:13:47,721] Trial 58 finished with value: 0.6469079939668175 and parameters: {'n_estimators': 630, 'max_depth': 27, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:13:53,770] Trial 59 finished with value: 0.6547511312217195 and parameters: {'n_estimators': 845, 'max_depth': 23, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:13:59,562] Trial 60 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 763, 'max_depth': 25, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:14:04,677] Trial 61 finished with value: 0.6587481146304676 and parameters: {'n_estimators': 655, 'max_depth': 19, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:14:09,955] Trial 62 finished with value: 0.6509803921568628 and parameters: {'n_estimators': 602, 'max_depth': 20, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:14:15,390] Trial 63 finished with value: 0.6625188536953243 and parameters: {'n_estimators': 710, 'max_depth': 21, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:14:21,262] Trial 64 finished with value: 0.6469834087481147 and parameters: {'n_estimators': 806, 'max_depth': 21, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:14:26,673] Trial 65 finished with value: 0.6625188536953243 and parameters: {'n_estimators': 713, 'max_depth': 22, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:14:32,488] Trial 66 finished with value: 0.6586726998491704 and parameters: {'n_estimators': 721, 'max_depth': 23, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:14:38,803] Trial 67 finished with value: 0.6430618401206636 and parameters: {'n_estimators': 894, 'max_depth': 26, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:14:42,963] Trial 68 finished with value: 0.596606334841629 and parameters: {'n_estimators': 549, 'max_depth': 22, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:14:47,401] Trial 69 finished with value: 0.6431372549019608 and parameters: {'n_estimators': 511, 'max_depth': 24, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:14:53,015] Trial 70 finished with value: 0.6509803921568628 and parameters: {'n_estimators': 742, 'max_depth': 28, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:14:58,223] Trial 71 finished with value: 0.6587481146304676 and parameters: {'n_estimators': 693, 'max_depth': 21, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:15:03,363] Trial 72 finished with value: 0.6587481146304676 and parameters: {'n_estimators': 620, 'max_depth': 25, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:15:09,187] Trial 73 finished with value: 0.6509049773755656 and parameters: {'n_estimators': 787, 'max_depth': 18, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:15:14,568] Trial 74 finished with value: 0.6586726998491704 and parameters: {'n_estimators': 707, 'max_depth': 17, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:15:19,854] Trial 75 finished with value: 0.6352187028657617 and parameters: {'n_estimators': 588, 'max_depth': 19, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:15:24,942] Trial 76 finished with value: 0.6587481146304676 and parameters: {'n_estimators': 656, 'max_depth': 22, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:15:30,619] Trial 77 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 763, 'max_depth': 21, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:15:35,646] Trial 78 finished with value: 0.6549019607843137 and parameters: {'n_estimators': 639, 'max_depth': 23, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:15:40,514] Trial 79 finished with value: 0.6160633484162896 and parameters: {'n_estimators': 741, 'max_depth': 13, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:15:45,193] Trial 80 finished with value: 0.6509049773755656 and parameters: {'n_estimators': 574, 'max_depth': 20, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[I 2024-06-14 14:15:50,368] Trial 81 finished with value: 0.6587481146304676 and parameters: {'n_estimators': 677, 'max_depth': 20, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 53 with value: 0.6625188536953243.\n",
      "[W 2024-06-14 14:15:52,046] Trial 82 failed with parameters: {'n_estimators': 656, 'max_depth': 22, 'max_features': 'sqrt', 'criterion': 'gini'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/c_/rs13jmts3nbf9xfm917mh9p80000gn/T/ipykernel_67895/953119682.py\", line 16, in rf_objective\n",
      "    scores = cross_val_score(pipe, x_train, y_train, cv=cv, scoring='accuracy')\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 719, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 430, in cross_validate\n",
      "    results = parallel(\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py\", line 1088, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 489, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py\", line 1088, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 192, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 239, in _fit\n",
      "    random_state = check_random_state(self.random_state)\n",
      "  File \"/Users/emmetthintz/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1397, in check_random_state\n",
      "    return np.random.RandomState(seed)\n",
      "  File \"numpy/random/mtrand.pyx\", line 184, in numpy.random.mtrand.RandomState.__init__\n",
      "  File \"_mt19937.pyx\", line 131, in numpy.random._mt19937.MT19937.__init__\n",
      "  File \"bit_generator.pyx\", line 535, in numpy.random.bit_generator.BitGenerator.__init__\n",
      "  File \"bit_generator.pyx\", line 315, in numpy.random.bit_generator.SeedSequence.__init__\n",
      "  File \"bit_generator.pyx\", line 389, in numpy.random.bit_generator.SeedSequence.get_assembled_entropy\n",
      "  File \"bit_generator.pyx\", line 140, in numpy.random.bit_generator._coerce_to_uint32_array\n",
      "  File \"bit_generator.pyx\", line 78, in numpy.random.bit_generator._int_to_uint32_array\n",
      "KeyboardInterrupt\n",
      "[W 2024-06-14 14:15:52,051] Trial 82 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     rf_study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m, pruner\u001b[38;5;241m=\u001b[39mpruner)\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mrf_study\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     save_study(rf_study, rf_study_filename)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[106], line 16\u001b[0m, in \u001b[0;36mrf_objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      9\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     10\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskb\u001b[39m\u001b[38;5;124m'\u001b[39m, SelectKBest(f_classif, k\u001b[38;5;241m=\u001b[39mk)),\n\u001b[1;32m     11\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpca\u001b[39m\u001b[38;5;124m'\u001b[39m, PCA(n_components\u001b[38;5;241m=\u001b[39mpca_components)),\n\u001b[1;32m     12\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39mn_estimators, max_depth\u001b[38;5;241m=\u001b[39mmax_depth, max_features\u001b[38;5;241m=\u001b[39mmax_features, criterion\u001b[38;5;241m=\u001b[39mcriterion, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     13\u001b[0m ])\n\u001b[1;32m     15\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/pipeline.py:475\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    474\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 475\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    201\u001b[0m         X,\n\u001b[1;32m    202\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    206\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/tree/_classes.py:239\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    233\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m     missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    238\u001b[0m ):\n\u001b[0;32m--> 239\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_random_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;66;03m# Need to validate separately here.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# We can't pass multi_output=True because that would allow y to be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask will check for finite values and\u001b[39;00m\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;66;03m# compute the missing mask if the tree supports missing values\u001b[39;00m\n\u001b[1;32m    248\u001b[0m         check_X_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    249\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    250\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/utils/validation.py:1397\u001b[0m, in \u001b[0;36mcheck_random_state\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mmtrand\u001b[38;5;241m.\u001b[39m_rand\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seed, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[0;32m-> 1397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRandomState\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seed, np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState):\n\u001b[1;32m   1399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m seed\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:184\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_mt19937.pyx:131\u001b[0m, in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mbit_generator.pyx:535\u001b[0m, in \u001b[0;36mnumpy.random.bit_generator.BitGenerator.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mbit_generator.pyx:315\u001b[0m, in \u001b[0;36mnumpy.random.bit_generator.SeedSequence.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mbit_generator.pyx:389\u001b[0m, in \u001b[0;36mnumpy.random.bit_generator.SeedSequence.get_assembled_entropy\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mbit_generator.pyx:140\u001b[0m, in \u001b[0;36mnumpy.random.bit_generator._coerce_to_uint32_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mbit_generator.pyx:78\u001b[0m, in \u001b[0;36mnumpy.random.bit_generator._int_to_uint32_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# RF Hyperparameter Optimization\n",
    "if os.path.exists(rf_study_filename):\n",
    "    rf_study = load_study(rf_study_filename)\n",
    "else:\n",
    "    rf_study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "    rf_study.optimize(rf_objective, n_trials=100)\n",
    "    save_study(rf_study, rf_study_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost Hyperparameter Optimization\n",
    "if os.path.exists(catboost_study_filename):\n",
    "    catboost_study = load_study(catboost_study_filename)\n",
    "else:\n",
    "    catboost_study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "    catboost_study.optimize(catboost_objective, n_trials=100)\n",
    "    save_study(catboost_study, catboost_study_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the best trial for each study\n",
    "\n",
    "For SVM, RF, and Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM trial:\n",
      "  Value:  0.6973604826546003\n",
      "  Params: \n",
      "    C: 0.17649644079910137\n",
      "    kernel: sigmoid\n"
     ]
    }
   ],
   "source": [
    "print(\"Best SVM trial:\")\n",
    "svm_trial = svm_study.best_trial\n",
    "print(\"  Value: \", svm_trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in svm_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest trial:\n",
      "  Value:  0.6625188536953243\n",
      "  Params: \n",
      "    n_estimators: 176\n",
      "    max_depth: 14\n",
      "    max_features: sqrt\n",
      "    criterion: gini\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Random Forest trial:\")\n",
    "rf_trial = rf_study.best_trial\n",
    "print(\"  Value: \", rf_trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in rf_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CatBoost trial:\n",
      "  Value:  0.6781297134238311\n",
      "  Params: \n",
      "    learning_rate: 0.24906236616145022\n",
      "    depth: 9\n",
      "    iterations: 504\n"
     ]
    }
   ],
   "source": [
    "print(\"Best CatBoost trial:\")\n",
    "catboost_trial = catboost_study.best_trial\n",
    "print(\"  Value: \", catboost_trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in catboost_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the models with the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the models with the best hyperparameters\n",
    "def train_and_evaluate(pipe, x_train, y_train, x_test, y_test):\n",
    "    pipe.fit(x_train, y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    print(f'Testing accuracy {accuracy_score(y_test, y_pred)}')\n",
    "    print(f'Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.5384615384615384\n",
      "Confusion matrix: \n",
      "[[23 12]\n",
      " [18 12]]\n"
     ]
    }
   ],
   "source": [
    "best_svm_params = svm_trial.params\n",
    "svm_pipe = Pipeline([\n",
    "    ('skb', SelectKBest(f_classif, k=feature_selection_num)),\n",
    "    ('pca', PCA(n_components=pca_components)),\n",
    "    ('estimator', SVC(C=best_svm_params['C'], kernel=best_svm_params['kernel'], random_state=0))\n",
    "])\n",
    "train_and_evaluate(svm_pipe, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.5230769230769231\n",
      "Confusion matrix: \n",
      "[[25 10]\n",
      " [21  9]]\n"
     ]
    }
   ],
   "source": [
    "best_rf_params = rf_trial.params\n",
    "rf_pipe = Pipeline([\n",
    "    ('skb', SelectKBest(f_classif, k=feature_selection_num)),\n",
    "    ('pca', PCA(n_components=pca_components)),\n",
    "    ('estimator', RandomForestClassifier(n_estimators=best_rf_params['n_estimators'],\n",
    "                                         max_depth=best_rf_params['max_depth'],\n",
    "                                         max_features=best_rf_params['max_features'],\n",
    "                                         criterion=best_rf_params['criterion'],\n",
    "                                         random_state=0))\n",
    "])\n",
    "train_and_evaluate(rf_pipe, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.5538461538461539\n",
      "Confusion matrix: \n",
      "[[26  9]\n",
      " [20 10]]\n"
     ]
    }
   ],
   "source": [
    "best_catboost_params = catboost_trial.params\n",
    "catboost_pipe = Pipeline([\n",
    "    ('skb', SelectKBest(f_classif, k=feature_selection_num)),\n",
    "    ('pca', PCA(n_components=pca_components)),\n",
    "    ('estimator', CatBoostClassifier(learning_rate=best_catboost_params['learning_rate'],\n",
    "                                     depth=best_catboost_params['depth'],\n",
    "                                     iterations=best_catboost_params['iterations'],\n",
    "                                     verbose=0,\n",
    "                                     random_state=0))\n",
    "])\n",
    "train_and_evaluate(catboost_pipe, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance and top features can be extracted similarly to the previous script\n",
    "def get_top_features(pipe, feature_names, top_feature_num):\n",
    "    if isinstance(pipe.named_steps['estimator'], SVC):\n",
    "        if pipe.named_steps['estimator'].kernel != 'linear':\n",
    "            raise ValueError(\"Feature importance is not available for non-linear SVM kernels.\")\n",
    "        feature_scores = pipe.named_steps['estimator'].coef_[0]\n",
    "    elif isinstance(pipe.named_steps['estimator'], RandomForestClassifier) or isinstance(pipe.named_steps['estimator'], CatBoostClassifier):\n",
    "        feature_scores = pipe.named_steps['estimator'].feature_importances_\n",
    "    features = pipe.named_steps['skb'].get_support(indices=True)\n",
    "    top_indices = np.argsort(np.abs(feature_scores))[::-1][:top_feature_num]\n",
    "    top_features = [(feature_names[i], feature_scores[i]) for i in top_indices]\n",
    "    return top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM feature extraction error: Feature importance is not available for non-linear SVM kernels.\n",
      "Top Random Forest features: [('hsa-miR-27a-5p', 0.06772062423945979), ('hsa-miR-451a', 0.023765754745985867), ('hsa-miR-1208', 0.020626936977291774), ('hsa-miR-196a-3p', 0.016040843256961496), ('hsa-miR-4802-5p', 0.0158484685333161), ('hsa-miR-520b', 0.015552219202958528), ('hsa-miR-512-3p', 0.01508621477718381), ('hsa-miR-5087', 0.015040522984511374), ('hsa-miR-6830-5p', 0.014859247441278698), ('hsa-miR-498', 0.014130820732006926), ('hsa-miR-8057', 0.013256015218894357), ('hsa-miR-3186-3p', 0.013187457599321882), ('hsa-miR-5583-5p', 0.012381345069653155), ('hsa-miR-490-3p', 0.011957701038942382), ('hsa-miR-518b', 0.011725159090626646), ('hsa-miR-5193', 0.011515990412170165), ('hsa-miR-6717-5p', 0.01141603118098908), ('hsa-miR-3140-5p', 0.011371810371700307), ('hsa-miR-4271', 0.010982738748211283), ('hsa-miR-2276-3p', 0.01096694286887455)]\n",
      "Top CatBoost features: [('hsa-miR-27a-5p', 16.664356944628125), ('hsa-miR-4424', 3.7504341909081464), ('hsa-miR-451a', 3.101456934664291), ('hsa-miR-34b-3p', 2.637879770624746), ('hsa-miR-3124-3p', 2.622124029174843), ('hsa-miR-512-3p', 2.2068340410291833), ('hsa-miR-2277-3p', 2.163770326791697), ('hsa-miR-498', 2.157822273867548), ('hsa-miR-452-5p', 2.038721790688345), ('hsa-miR-3973', 1.9940130098141433), ('hsa-miR-548l', 1.9811468032442168), ('hsa-miR-92a-3p', 1.96437209556267), ('hsa-miR-4722-3p', 1.849136135732754), ('hsa-miR-6813-3p', 1.7204271956361663), ('hsa-miR-3140-5p', 1.674076342651285), ('hsa-miR-5193', 1.65678706412624), ('hsa-miR-4802-5p', 1.6214371555098586), ('hsa-miR-568', 1.5623965363777177), ('hsa-miR-490-3p', 1.4976700339797828), ('hsa-miR-513a-5p', 1.4210949476522787)]\n"
     ]
    }
   ],
   "source": [
    "# Get top features for each model\n",
    "try:\n",
    "    svm_top_features = get_top_features(svm_pipe, feature_names, feature_importance_num)\n",
    "    print(\"Top SVM features:\", svm_top_features)\n",
    "except ValueError as e:\n",
    "    print(\"SVM feature extraction error:\", e)\n",
    "\n",
    "rf_top_features = get_top_features(rf_pipe, feature_names, feature_importance_num)\n",
    "catboost_top_features = get_top_features(catboost_pipe, feature_names, feature_importance_num)\n",
    "\n",
    "print(\"Top Random Forest features:\", rf_top_features)\n",
    "print(\"Top CatBoost features:\", catboost_top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hsa-miR-27a-5p\n",
      "hsa-miR-451a\n",
      "hsa-miR-1208\n",
      "hsa-miR-196a-3p\n",
      "hsa-miR-4802-5p\n",
      "hsa-miR-520b\n",
      "hsa-miR-512-3p\n",
      "hsa-miR-5087\n",
      "hsa-miR-6830-5p\n",
      "hsa-miR-498\n",
      "hsa-miR-8057\n",
      "hsa-miR-3186-3p\n",
      "hsa-miR-5583-5p\n",
      "hsa-miR-490-3p\n",
      "hsa-miR-518b\n",
      "hsa-miR-5193\n",
      "hsa-miR-6717-5p\n",
      "hsa-miR-3140-5p\n",
      "hsa-miR-4271\n",
      "hsa-miR-2276-3p\n",
      "hsa-miR-27a-5p\n",
      "hsa-miR-4424\n",
      "hsa-miR-451a\n",
      "hsa-miR-34b-3p\n",
      "hsa-miR-3124-3p\n",
      "hsa-miR-512-3p\n",
      "hsa-miR-2277-3p\n",
      "hsa-miR-498\n",
      "hsa-miR-452-5p\n",
      "hsa-miR-3973\n",
      "hsa-miR-548l\n",
      "hsa-miR-92a-3p\n",
      "hsa-miR-4722-3p\n",
      "hsa-miR-6813-3p\n",
      "hsa-miR-3140-5p\n",
      "hsa-miR-5193\n",
      "hsa-miR-4802-5p\n",
      "hsa-miR-568\n",
      "hsa-miR-490-3p\n",
      "hsa-miR-513a-5p\n"
     ]
    }
   ],
   "source": [
    "# Compile and print the list of top features\n",
    "def compile_top_features_list(rf_features, cb_features):\n",
    "    top_features = rf_features + cb_features\n",
    "    feature_names = [feature[0] for feature in top_features]\n",
    "    return '\\n'.join(feature_names)\n",
    "\n",
    "top_features_list = compile_top_features_list(rf_top_features, catboost_top_features)\n",
    "print(top_features_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
